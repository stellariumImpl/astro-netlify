---
title: "Machine Learning & Data Mining"
description: "The revision of COMP9417"
image: "../assets/wallhaven-1p7853.png"
createdAt: 04-27-2025
draft: false
tags:
  - 模型分类
---

## 模型分类方式

### 判别模型和生成模型

- 判别模型：学习条件概率P(Y|X)，也可以学习决策边界，目标是直接分类，不考虑数据是如何生成

    代表有逻辑回归、SVM、感知机perception、k近邻算法KNN、决策树、随机森林、梯度提升树（GBDT、XGBoost、LightGBM）Boosting框架下的判别模型、神经网络（MLP、CNN、RNN）非线性函数近似器。

- 生成模型：学习联合概率P(X,Y)，也可以学习边际概率P(X)或条件概率P(Y|X)，利用贝叶斯定理，然后用MAP进行分类。

    代表有朴素贝叶斯（假设特征条件独立估计P(X,Y)）、GMM（高斯混合模型）。

### 概率模型与非概率模型

- 概率模型：建模的是数据的概率分布，通常学习P(X)或P(X|Y)或联合分布P(X,Y)，模型的输出是一个概率值或者概率驱动的。

    代表有朴素贝叶斯分类器、贝叶斯网络、GMM（高斯混合模型）、逻辑回归。

- 非概率模型：不直接建立概率分布，而是输出一个确定性的函数结果（决策边界、标签值）。

    代表有决策树、SVM、k近邻算法KNN、感知机perception。

### 监督学习与无监督学习

- 监督学习：训练数据包含输入特征和对应的标签，模型通过学习输入特征与标签之间的关系来进行预测。

    代表有线性回归、逻辑回归、决策树、随机森林、SVM、k近邻算法KNN、神经网络。

- 无监督学习：训练数据仅包含输入特征，没有标签，模型通过学习输入特征之间的关系来进行聚类或降维，目标是数据挖掘。

    代表有k均值聚类、层次聚类、主成分分析PCA、GMM（高斯混合模型）、Autoencoder（自编码器）。

### 线性模型与非线性模型

- 线性模型：模型输出是输入特征的线性组合。

    代表有线性回归、逻辑回归、感知机perception、线性SVM。

- 非线性模型：模型中包含非线性关系，不能用单一的线性函数来表示。

    代表有决策树、神经网络、非线性SVM（非线性核函数）、k近邻算法KNN。

### 稳定模型与不稳定模型

稳定性：用来描述学习算法对训练数据微小变化的敏感程度。

- 稳定模型：对于训练数据的小幅度变化不敏感，即使训练集略有改动，模型输出基本不变。

    代表有k近邻算法KNN和线性回归，他们的方差较低，预测结果平稳，所以通过集成学习方法（如Bagging）对其性能提升不明显。

- 不稳定模型：对于训练数据的小幅度变化敏感，即使训练集略有改动，模型输出也会发生较大变化。

    代表有决策树，他们具有较高的方差，容易过拟合训练数据，通过集成多个模型（如Bagging）可以有效降低方差，提升模型泛化能力。



